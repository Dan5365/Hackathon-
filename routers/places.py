# —Ä–∞–±–æ—Ç–∞ —Å 2GIS API
# routers/places.py
from fastapi import APIRouter
import requests
import os
import pandas as pd
import json
from dotenv import load_dotenv

load_dotenv()
router = APIRouter(prefix="/api/places", tags=["Places"])

# API-–∫–ª—é—á 2GIS
API_KEY = "401b0774-dbe8-4f70-91c9-697adac3e650"

DATA_DIR = "data/raw"
META_DIR = "data/meta"
FILE_PATH = os.path.join(DATA_DIR, "places.csv")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(META_DIR, exist_ok=True)

# --- üîß –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def safe_float(value):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float"""
    try:
        v = float(value)
        if v == float("inf") or v == float("-inf"):
            return None
        return v
    except Exception:
        return None

def extract_contacts(contact_groups):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω—ã"""
    if not contact_groups:
        return ""
    phones = []
    for group in contact_groups:
        for contact in group.get("contacts", []):
            if contact.get("type") == "phone":
                phones.append(contact.get("value"))
    return ", ".join(phones)

def extract_coords(point):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã"""
    if not point:
        return "", None, None
    lat = safe_float(point.get("lat"))
    lon = safe_float(point.get("lon"))
    coords = f"{lat}, {lon}" if lat and lon else ""
    return coords, lat, lon

def extract_schedule(item):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤ JSON"""
    schedule = item.get("schedule")
    if not schedule:
        return ""
    try:
        return json.dumps(schedule, ensure_ascii=False)
    except Exception:
        return str(schedule)

# --- üöÄ –û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç ---
@router.get("/")
def get_places(query: str = "–≥–ª—ç–º–ø–∏–Ω–≥", city: str = "–ê–ª–º–∞—Ç—ã", region_id: int = 12):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ 2GIS –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ data/raw/places.csv.
    –¢–∞–∫–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å (query, city) –≤ data/meta/.
    """
    url = "https://catalog.api.2gis.com/3.0/items"
    params = {"q": query, "region_id": region_id, "key": API_KEY, "page_size": 50}
    resp = requests.get(url, params=params).json()

    if resp.get("meta", {}).get("code") != 200:
        return {"error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ 2GIS API", "details": resp.get("meta")}

    items = resp.get("result", {}).get("items", [])
    if not items:
        return {"status": "no_results", "query": query, "city": city}

    results = []
    for item in items:
        coords, lat, lon = extract_coords(item.get("point"))
        results.append({
            "name": item.get("name", ""),
            "address": item.get("address_name", ""),
            "contacts": extract_contacts(item.get("contact_groups")),
            "coords": coords,
            "category": item.get("rubrics")[0]["name"] if item.get("rubrics") else "",
            "lat": lat,
            "lon": lon,
            "schedule": extract_schedule(item),
            "query": query,
            "city": city
        })

    # --- üì¶ –ß—Ç–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
    if os.path.exists(FILE_PATH) and os.path.getsize(FILE_PATH) > 0:
        try:
            old_df = pd.read_csv(FILE_PATH)
        except Exception:
            old_df = pd.DataFrame(columns=results[0].keys())
    else:
        old_df = pd.DataFrame(columns=results[0].keys())

    # --- üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞ ---
    new_df = pd.DataFrame(results)
    combined_df = pd.concat([old_df, new_df], ignore_index=True)
    combined_df = combined_df.drop_duplicates(subset=["name", "address"], keep="last")
    combined_df = combined_df.fillna("")

    # --- üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ---
    combined_df.to_csv(FILE_PATH, index=False, encoding="utf-8")

    # --- üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ---
    with open(os.path.join(META_DIR, "last_query.txt"), "w", encoding="utf-8") as f:
        f.write(query.strip())
    with open(os.path.join(META_DIR, "last_city.txt"), "w", encoding="utf-8") as f:
        f.write(city.strip())

    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤: {len(new_df)} (–∑–∞–ø—Ä–æ—Å: {query}, –≥–æ—Ä–æ–¥: {city})")
    print(f"üìÅ –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(combined_df)} –∑–∞–ø–∏—Å–µ–π")

    return {
        "status": "success",
        "query": query,
        "city": city,
        "count_new": len(new_df),
        "total_saved": len(combined_df),
        "file": FILE_PATH,
        "sample": combined_df.tail(3).to_dict(orient="records")
    }
